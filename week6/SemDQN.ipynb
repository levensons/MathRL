{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRwMNuvir5g5",
        "outputId": "42c19dd3-1b88-42c1-975f-3eeeda7e464c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gym[accept-rom-license,atari,classic_control,mujoco]==0.25.2 in /usr/local/lib/python3.10/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym[accept-rom-license,atari,classic_control,mujoco]==0.25.2) (1.23.5)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym[accept-rom-license,atari,classic_control,mujoco]==0.25.2) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym[accept-rom-license,atari,classic_control,mujoco]==0.25.2) (0.0.8)\n",
            "Collecting pygame==2.1.0 (from gym[accept-rom-license,atari,classic_control,mujoco]==0.25.2)\n",
            "  Downloading pygame-2.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ale-py~=0.7.5 (from gym[accept-rom-license,atari,classic_control,mujoco]==0.25.2)\n",
            "  Downloading ale_py-0.7.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m84.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mujoco==2.2.0 (from gym[accept-rom-license,atari,classic_control,mujoco]==0.25.2)\n",
            "  Downloading mujoco-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: imageio>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from gym[accept-rom-license,atari,classic_control,mujoco]==0.25.2) (2.31.6)\n",
            "Collecting autorom[accept-rom-license]~=0.4.2 (from gym[accept-rom-license,atari,classic_control,mujoco]==0.25.2)\n",
            "  Downloading AutoROM-0.4.2-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mujoco==2.2.0->gym[accept-rom-license,atari,classic_control,mujoco]==0.25.2) (1.4.0)\n",
            "Collecting glfw (from mujoco==2.2.0->gym[accept-rom-license,atari,classic_control,mujoco]==0.25.2)\n",
            "  Downloading glfw-2.6.3-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38-none-manylinux2014_x86_64.whl (208 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.2/208.2 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyopengl in /usr/local/lib/python3.10/dist-packages (from mujoco==2.2.0->gym[accept-rom-license,atari,classic_control,mujoco]==0.25.2) (3.1.7)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from ale-py~=0.7.5->gym[accept-rom-license,atari,classic_control,mujoco]==0.25.2) (6.1.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari,classic_control,mujoco]==0.25.2) (8.1.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari,classic_control,mujoco]==0.25.2) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari,classic_control,mujoco]==0.25.2) (4.66.1)\n",
            "Collecting AutoROM.accept-rom-license (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari,classic_control,mujoco]==0.25.2)\n",
            "  Downloading AutoROM.accept-rom-license-0.6.1.tar.gz (434 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.7/434.7 kB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pillow<10.1.0,>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio>=2.14.1->gym[accept-rom-license,atari,classic_control,mujoco]==0.25.2) (9.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari,classic_control,mujoco]==0.25.2) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari,classic_control,mujoco]==0.25.2) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari,classic_control,mujoco]==0.25.2) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari,classic_control,mujoco]==0.25.2) (2023.11.17)\n",
            "Building wheels for collected packages: AutoROM.accept-rom-license\n",
            "  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.6.1-py3-none-any.whl size=446660 sha256=8596a1d74660e49b116b29f433bc7ccc6a94533551d6bab16858c45d4635ba27\n",
            "  Stored in directory: /root/.cache/pip/wheels/6b/1b/ef/a43ff1a2f1736d5711faa1ba4c1f61be1131b8899e6a057811\n",
            "Successfully built AutoROM.accept-rom-license\n",
            "Installing collected packages: glfw, pygame, mujoco, ale-py, AutoROM.accept-rom-license, autorom\n",
            "  Attempting uninstall: pygame\n",
            "    Found existing installation: pygame 2.5.2\n",
            "    Uninstalling pygame-2.5.2:\n",
            "      Successfully uninstalled pygame-2.5.2\n",
            "Successfully installed AutoROM.accept-rom-license-0.6.1 ale-py-0.7.5 autorom-0.4.2 glfw-2.6.3 mujoco-2.2.0 pygame-2.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install gym[classic_control,mujoco,atari,accept-rom-license]==0.25.2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Sequence, Callable, Tuple, Optional, Union, List, Dict\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "import cv2\n",
        "\n",
        "import gym\n",
        "from gym import wrappers\n",
        "from gym.wrappers.record_episode_statistics import RecordEpisodeStatistics\n",
        "\n",
        "import time\n",
        "import argparse\n",
        "import os\n",
        "\n",
        "import tqdm\n",
        "\n",
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import animation\n",
        "from IPython.display import display, clear_output, HTML\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "SYS5mLAqt5Xa"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXemii7l855V",
        "outputId": "9cd890e3-6e63-4b41-8d2f-05ac572e9d50"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def from_numpy(data: Union[np.ndarray, dict], **kwargs):\n",
        "    if isinstance(data, dict):\n",
        "        return {k: from_numpy(v) for k, v in data.items()}\n",
        "    else:\n",
        "        data = torch.from_numpy(data, **kwargs)\n",
        "        if data.dtype == torch.float64:\n",
        "            data = data.float()\n",
        "        return data.to(device)\n",
        "\n",
        "def to_numpy(tensor: Union[torch.Tensor, dict]):\n",
        "    if isinstance(tensor, dict):\n",
        "        return {k: to_numpy(v) for k, v in tensor.items()}\n",
        "    else:\n",
        "        return tensor.to(\"cpu\").detach().numpy()"
      ],
      "metadata": {
        "id": "d6cyDlR598Kt"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DQNAgent(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        observation_shape: Sequence[int],\n",
        "        num_actions: int,\n",
        "        make_critic: Callable[[Tuple[int, ...], int], nn.Module],\n",
        "        make_optimizer: Callable[[torch.nn.ParameterList], torch.optim.Optimizer],\n",
        "        make_lr_schedule: Callable[\n",
        "            [torch.optim.Optimizer], torch.optim.lr_scheduler._LRScheduler\n",
        "        ],\n",
        "        discount: float,\n",
        "        target_update_period: int,\n",
        "        use_double_q: bool = False,\n",
        "        clip_grad_norm: Optional[float] = None,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.critic = make_critic(observation_shape, num_actions)\n",
        "        self.target_critic = make_critic(observation_shape, num_actions)\n",
        "        self.critic_optimizer = make_optimizer(self.critic.parameters())\n",
        "        self.lr_scheduler = make_lr_schedule(self.critic_optimizer)\n",
        "\n",
        "        self.observation_shape = observation_shape\n",
        "        self.num_actions = num_actions\n",
        "        self.discount = discount\n",
        "        self.target_update_period = target_update_period\n",
        "        self.clip_grad_norm = clip_grad_norm\n",
        "        self.use_double_q = use_double_q\n",
        "\n",
        "        self.critic_loss = nn.MSELoss()\n",
        "\n",
        "        self.update_target_critic()\n",
        "\n",
        "    def get_action(self, observation: np.ndarray, epsilon: float = 0.02) -> int:\n",
        "        \"\"\"\n",
        "        Used for evaluation.\n",
        "        \"\"\"\n",
        "        observation = from_numpy(np.asarray(observation))[None]\n",
        "\n",
        "        # TODO: get the action from the critic using an epsilon-greedy strategy\n",
        "        if np.random.uniform() < epsilon:\n",
        "            action = torch.randint(0, self.num_actions, (observation.shape[0],))\n",
        "        else:\n",
        "            action = self.critic(observation).argmax(dim=-1)\n",
        "\n",
        "        return to_numpy(action).squeeze(0).item()\n",
        "\n",
        "    def update_critic(\n",
        "        self,\n",
        "        obs: torch.Tensor,\n",
        "        action: torch.Tensor,\n",
        "        reward: torch.Tensor,\n",
        "        next_obs: torch.Tensor,\n",
        "        done: torch.Tensor,\n",
        "    ) -> dict:\n",
        "        \"\"\"Update the DQN critic, and return stats for logging.\"\"\"\n",
        "        (batch_size,) = reward.shape\n",
        "\n",
        "        # Compute target values\n",
        "        with torch.no_grad():\n",
        "            # TODO: compute target values\n",
        "            next_qa_values = self.target_critic(next_obs)\n",
        "\n",
        "            if self.use_double_q:\n",
        "                raise NotImplementedError\n",
        "            else:\n",
        "                next_action = next_qa_values.argmax(dim=-1, keepdim=True)\n",
        "\n",
        "            next_q_values = torch.gather(next_qa_values, -1, next_action)\n",
        "            target_values = reward.unsqueeze(-1) + self.discount * next_q_values\n",
        "            target_values = torch.where(done, reward, target_values.squeeze(-1))\n",
        "\n",
        "        # TODO: train the critic with the target values\n",
        "        qa_values = self.critic(obs)\n",
        "        q_values = torch.gather(qa_values, -1, action.unsqueeze(-1)).squeeze(-1) # Compute from the data actions; see torch.gather\n",
        "        loss = self.critic_loss(q_values, target_values)\n",
        "\n",
        "\n",
        "        self.critic_optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        grad_norm = torch.nn.utils.clip_grad.clip_grad_norm_(\n",
        "            self.critic.parameters(), self.clip_grad_norm or float(\"inf\")\n",
        "        )\n",
        "        self.critic_optimizer.step()\n",
        "\n",
        "        self.lr_scheduler.step()\n",
        "\n",
        "        return {\n",
        "            \"critic_loss\": loss.item(),\n",
        "            \"q_values\": q_values.mean().item(),\n",
        "            \"target_values\": target_values.mean().item(),\n",
        "            \"grad_norm\": grad_norm.item(),\n",
        "        }\n",
        "\n",
        "    def update_target_critic(self):\n",
        "        self.target_critic.load_state_dict(self.critic.state_dict())\n",
        "\n",
        "    def update(\n",
        "        self,\n",
        "        obs: torch.Tensor,\n",
        "        action: torch.Tensor,\n",
        "        reward: torch.Tensor,\n",
        "        next_obs: torch.Tensor,\n",
        "        done: torch.Tensor,\n",
        "        step: int,\n",
        "    ) -> dict:\n",
        "        \"\"\"\n",
        "        Update the DQN agent, including both the critic and target.\n",
        "        \"\"\"\n",
        "        # TODO: update the critic, and the target if needed\n",
        "        critic_stats = self.update_critic(obs,\n",
        "                                          action,\n",
        "                                          reward,\n",
        "                                          next_obs,\n",
        "                                          done)\n",
        "\n",
        "        if step % self.target_update_period == 0:\n",
        "            self.update_target_critic()\n",
        "\n",
        "        return critic_stats"
      ],
      "metadata": {
        "id": "vn9o_OtbsWFg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ReplayBuffer:\n",
        "    def __init__(self, capacity=1000000):\n",
        "        self.max_size = capacity\n",
        "        self.size = 0\n",
        "        self.observations = None\n",
        "        self.actions = None\n",
        "        self.rewards = None\n",
        "        self.next_observations = None\n",
        "        self.dones = None\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        rand_indices = np.random.randint(0, self.size, size=(batch_size,)) % self.max_size\n",
        "        return {\n",
        "            \"observations\": self.observations[rand_indices],\n",
        "            \"actions\": self.actions[rand_indices],\n",
        "            \"rewards\": self.rewards[rand_indices],\n",
        "            \"next_observations\": self.next_observations[rand_indices],\n",
        "            \"dones\": self.dones[rand_indices],\n",
        "        }\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.size\n",
        "\n",
        "    def insert(\n",
        "        self,\n",
        "        /,\n",
        "        observation: np.ndarray,\n",
        "        action: np.ndarray,\n",
        "        reward: np.ndarray,\n",
        "        next_observation: np.ndarray,\n",
        "        done: np.ndarray,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Insert a single transition into the replay buffer.\n",
        "\n",
        "        Use like:\n",
        "            replay_buffer.insert(\n",
        "                observation=observation,\n",
        "                action=action,\n",
        "                reward=reward,\n",
        "                next_observation=next_observation,\n",
        "                done=done,\n",
        "            )\n",
        "        \"\"\"\n",
        "        if isinstance(reward, (float, int)):\n",
        "            reward = np.array(reward)\n",
        "        if isinstance(done, bool):\n",
        "            done = np.array(done)\n",
        "        if isinstance(action, int):\n",
        "            action = np.array(action, dtype=np.int64)\n",
        "\n",
        "        if self.observations is None:\n",
        "            self.observations = np.empty(\n",
        "                (self.max_size, *observation.shape), dtype=observation.dtype\n",
        "            )\n",
        "            self.actions = np.empty((self.max_size, *action.shape), dtype=action.dtype)\n",
        "            self.rewards = np.empty((self.max_size, *reward.shape), dtype=reward.dtype)\n",
        "            self.next_observations = np.empty(\n",
        "                (self.max_size, *next_observation.shape), dtype=next_observation.dtype\n",
        "            )\n",
        "            self.dones = np.empty((self.max_size, *done.shape), dtype=done.dtype)\n",
        "\n",
        "        assert observation.shape == self.observations.shape[1:]\n",
        "        assert action.shape == self.actions.shape[1:]\n",
        "        assert reward.shape == ()\n",
        "        assert next_observation.shape == self.next_observations.shape[1:]\n",
        "        assert done.shape == ()\n",
        "\n",
        "        self.observations[self.size % self.max_size] = observation\n",
        "        self.actions[self.size % self.max_size] = action\n",
        "        self.rewards[self.size % self.max_size] = reward\n",
        "        self.next_observations[self.size % self.max_size] = next_observation\n",
        "        self.dones[self.size % self.max_size] = done\n",
        "\n",
        "        self.size += 1"
      ],
      "metadata": {
        "id": "-vZVR8byyotW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_trajectory(\n",
        "    env: gym.Env, policy, max_length: int, render: bool = False\n",
        ") -> Dict[str, np.ndarray]:\n",
        "    \"\"\"Sample a rollout in the environment from a policy.\"\"\"\n",
        "    ob = env.reset()\n",
        "    obs, acs, rewards, next_obs, terminals, image_obs = [], [], [], [], [], []\n",
        "    steps = 0\n",
        "\n",
        "    while True:\n",
        "        # render an image\n",
        "        if render:\n",
        "            if hasattr(env, \"sim\"):\n",
        "                img = env.sim.render(camera_name=\"track\", height=500, width=500)[::-1]\n",
        "            else:\n",
        "                img = env.render(mode=\"rgb_array\")\n",
        "\n",
        "            if isinstance(img, list):\n",
        "                img = img[0]\n",
        "\n",
        "            image_obs.append(\n",
        "                cv2.resize(img, dsize=(250, 250), interpolation=cv2.INTER_CUBIC)\n",
        "            )\n",
        "\n",
        "        ac = policy.get_action(ob)\n",
        "\n",
        "        next_ob, rew, done, info = env.step(ac)\n",
        "\n",
        "        steps += 1\n",
        "        rollout_done = done or steps > max_length\n",
        "\n",
        "        # record result of taking that action\n",
        "        obs.append(ob)\n",
        "        acs.append(ac)\n",
        "        rewards.append(rew)\n",
        "        next_obs.append(next_ob)\n",
        "        terminals.append(rollout_done)\n",
        "\n",
        "        ob = next_ob  # jump to next timestep\n",
        "\n",
        "        # end the rollout if the rollout ended\n",
        "        if rollout_done:\n",
        "            break\n",
        "\n",
        "    episode_statistics = {\"l\": steps, \"r\": np.sum(rewards)}\n",
        "    if \"episode\" in info:\n",
        "        episode_statistics.update(info[\"episode\"])\n",
        "\n",
        "    env.close()\n",
        "\n",
        "    return {\n",
        "        \"observation\": np.array(obs, dtype=np.float32),\n",
        "        \"image_obs\": np.array(image_obs, dtype=np.uint8),\n",
        "        \"reward\": np.array(rewards, dtype=np.float32),\n",
        "        \"action\": np.array(acs, dtype=np.float32),\n",
        "        \"next_observation\": np.array(next_obs, dtype=np.float32),\n",
        "        \"terminal\": np.array(terminals, dtype=np.float32),\n",
        "        \"episode_statistics\": episode_statistics,\n",
        "    }\n",
        "\n",
        "def sample_n_trajectories(\n",
        "    env: gym.Env, policy, ntraj: int, max_length: int, render: bool = False\n",
        "):\n",
        "    \"\"\"Collect ntraj rollouts.\"\"\"\n",
        "    trajs = []\n",
        "    for _ in range(ntraj):\n",
        "        # collect rollout\n",
        "        traj = sample_trajectory(env, policy, max_length, render)\n",
        "        trajs.append(traj)\n",
        "    return trajs\n",
        "\n",
        "def log_paths_as_videos(paths, max_videos_to_save=2):\n",
        "        # reshape the rollouts\n",
        "        # videos = [np.transpose(p['image_obs'], [0, 3, 1, 2]) for p in paths]\n",
        "        videos = [p['image_obs'] for p in paths]\n",
        "\n",
        "        # max rollout length\n",
        "        max_videos_to_save = np.min([max_videos_to_save, len(videos)])\n",
        "        max_length = videos[0].shape[0]\n",
        "        for i in range(max_videos_to_save):\n",
        "            if videos[i].shape[0]>max_length:\n",
        "                max_length = videos[i].shape[0]\n",
        "\n",
        "        # pad rollouts to all be same length\n",
        "        for i in range(max_videos_to_save):\n",
        "            if videos[i].shape[0]<max_length:\n",
        "                padding = np.tile([videos[i][-1]], (max_length-videos[i].shape[0],1,1,1))\n",
        "                videos[i] = np.concatenate([videos[i], padding], 0)\n",
        "\n",
        "        # log videos to tensorboard event file\n",
        "        videos = np.stack(videos[:max_videos_to_save], 0)\n",
        "\n",
        "        return videos\n",
        "\n",
        "def plot_trajectories(videos):\n",
        "    fig = plt.figure()\n",
        "    imgs = []\n",
        "\n",
        "    n_trajs = videos.shape[0]\n",
        "    for i in range(1, n_trajs + 1):\n",
        "        fig.add_subplot(1, n_trajs, i)\n",
        "        imgs.append(plt.imshow(videos[i - 1, 0, ...]))\n",
        "\n",
        "    plt.close() # this is required to not display the generated image\n",
        "\n",
        "    def init():\n",
        "        for j, im in enumerate(imgs):\n",
        "            im.set_data(videos[j, 0, ...])\n",
        "\n",
        "        return imgs\n",
        "\n",
        "    def animate(i):\n",
        "        for j, im in enumerate(imgs):\n",
        "            im.set_data(videos[j, i, ...])\n",
        "\n",
        "        return imgs\n",
        "\n",
        "    anim = animation.FuncAnimation(fig,\n",
        "                                   animate,\n",
        "                                   init_func=init,\n",
        "                                   frames=videos.shape[1],\n",
        "                                   interval=25,\n",
        "                                   repeat=False)\n",
        "                                #    repeat_delay=1000)\n",
        "\n",
        "    clear_output(True)\n",
        "    display(HTML(anim.to_html5_video()))\n",
        "\n",
        "def run_training_loop(config,\n",
        "                      seed=42):\n",
        "    # set random seeds\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "    env = config[\"make_env\"]()\n",
        "    eval_env = config[\"make_env\"]()\n",
        "    # render_env = RecordVideo(config[\"make_env\"](render=True), video_folder=\"videos\")\n",
        "    render_env = config[\"make_env\"](render=True)\n",
        "\n",
        "    # make the gym environment\n",
        "    exploration_schedule = config[\"exploration_schedule\"]\n",
        "    discrete = isinstance(env.action_space, gym.spaces.Discrete)\n",
        "\n",
        "    assert discrete, \"DQN only supports discrete action spaces\"\n",
        "\n",
        "    agent = DQNAgent(\n",
        "        env.observation_space.shape,\n",
        "        env.action_space.n,\n",
        "        **config[\"agent_kwargs\"],\n",
        "    )\n",
        "\n",
        "    # simulation timestep, will be used for video saving\n",
        "    if \"model\" in dir(env):\n",
        "        fps = 1 / env.model.opt.timestep\n",
        "    elif \"render_fps\" in env.env.metadata:\n",
        "        fps = env.env.metadata[\"render_fps\"]\n",
        "    else:\n",
        "        fps = 4\n",
        "\n",
        "    ep_len = env.spec.max_episode_steps\n",
        "\n",
        "    observation = None\n",
        "\n",
        "    stacked_frames = False\n",
        "    replay_buffer = ReplayBuffer()\n",
        "\n",
        "    def reset_env_training():\n",
        "        nonlocal observation\n",
        "\n",
        "        observation = env.reset()\n",
        "\n",
        "        assert not isinstance(\n",
        "            observation, tuple\n",
        "        ), \"env.reset() must return np.ndarray - make sure your Gym version uses the old step API\"\n",
        "        observation = np.asarray(observation)\n",
        "\n",
        "    reset_env_training()\n",
        "\n",
        "    stats = {}\n",
        "\n",
        "    t = tqdm.trange(config[\"total_steps\"], dynamic_ncols=True)\n",
        "\n",
        "    for step in t:\n",
        "        epsilon = exploration_schedule.value(step)\n",
        "\n",
        "        # TODO: Compute action\n",
        "        action = agent.get_action(observation, epsilon)\n",
        "\n",
        "        # TODO: Step the environment\n",
        "        next_observation, reward, done, info = env.step(action)\n",
        "\n",
        "        next_observation = np.asarray(next_observation)\n",
        "        truncated = info.get(\"TimeLimit.truncated\", False)\n",
        "\n",
        "        # TODO: Add the data to the replay buffer\n",
        "        replay_buffer.insert(observation=observation,\n",
        "                             action=action,\n",
        "                             reward=reward,\n",
        "                             next_observation=next_observation,\n",
        "                             done=(not truncated) and done)\n",
        "\n",
        "        # Handle episode termination\n",
        "        if done:\n",
        "            reset_env_training()\n",
        "        else:\n",
        "            observation = next_observation\n",
        "\n",
        "        # Main DQN training loop\n",
        "        if step >= config[\"learning_starts\"]:\n",
        "            # TODO: Sample config[\"batch_size\"] samples from the replay buffer\n",
        "            batch = replay_buffer.sample(config[\"batch_size\"])\n",
        "\n",
        "            # Convert to PyTorch tensors\n",
        "            batch = from_numpy(batch)\n",
        "\n",
        "            # TODO: Train the agent. `batch` is a dictionary of numpy arrays,\n",
        "            update_info = agent.update(batch[\"observations\"],\n",
        "                                       batch[\"actions\"],\n",
        "                                       batch[\"rewards\"],\n",
        "                                       batch[\"next_observations\"],\n",
        "                                       batch[\"dones\"],\n",
        "                                       step)\n",
        "\n",
        "            # Logging code\n",
        "            update_info[\"epsilon\"] = epsilon\n",
        "            update_info[\"lr\"] = agent.lr_scheduler.get_last_lr()[0]\n",
        "\n",
        "            if step % config[\"log_interval\"] == 0:\n",
        "                for k, v in update_info.items():\n",
        "                    stats[k] = v\n",
        "\n",
        "                t.set_postfix(stats, refresh=True)\n",
        "\n",
        "        if step % config[\"eval_interval\"] == 0:\n",
        "            # Evaluate\n",
        "            trajectories = sample_n_trajectories(\n",
        "                eval_env,\n",
        "                agent,\n",
        "                config[\"num_eval_trajectories\"],\n",
        "                ep_len,\n",
        "            )\n",
        "            returns = [t[\"episode_statistics\"][\"r\"] for t in trajectories]\n",
        "            ep_lens = [t[\"episode_statistics\"][\"l\"] for t in trajectories]\n",
        "\n",
        "            stats[\"eval_return\"] = np.mean(returns)\n",
        "            stats[\"eval_ep_len\"] = np.mean(ep_lens)\n",
        "\n",
        "            if len(returns) > 1:\n",
        "                stats[\"eval/return_std\"] = np.std(returns)\n",
        "                stats[\"eval/return_max\"] = np.max(returns)\n",
        "                stats[\"eval/return_min\"] = np.min(returns)\n",
        "                stats[\"eval/ep_len_std\"] = np.std(ep_lens)\n",
        "                stats[\"eval/ep_len_max\"] = np.max(ep_lens)\n",
        "                stats[\"eval/ep_len_min\"] = np.min(ep_lens)\n",
        "\n",
        "                t.set_postfix(stats, refresh=True)\n",
        "\n",
        "            if config[\"num_render_trajectories\"] > 0:\n",
        "                video_trajectories = sample_n_trajectories(\n",
        "                    render_env,\n",
        "                    agent,\n",
        "                    config[\"num_render_trajectories\"],\n",
        "                    ep_len,\n",
        "                    render=True,\n",
        "                )\n",
        "\n",
        "                videos = log_paths_as_videos(video_trajectories,\n",
        "                                             max_videos_to_save=5)\n",
        "\n",
        "                plot_trajectories(videos)\n"
      ],
      "metadata": {
        "id": "ndjJQkDHuhEc"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearSchedule(object):\n",
        "    def __init__(self, schedule_timesteps, final_p, initial_p=1.0):\n",
        "        \"\"\"Linear interpolation between initial_p and final_p over\n",
        "        schedule_timesteps. After this many timesteps pass final_p is\n",
        "        returned.\n",
        "        Parameters\n",
        "        ----------\n",
        "        schedule_timesteps: int\n",
        "            Number of timesteps for which to linearly anneal initial_p\n",
        "            to final_p\n",
        "        initial_p: float\n",
        "            initial output value\n",
        "        final_p: float\n",
        "            final output value\n",
        "        \"\"\"\n",
        "        self.schedule_timesteps = schedule_timesteps\n",
        "        self.final_p            = final_p\n",
        "        self.initial_p          = initial_p\n",
        "\n",
        "    def value(self, t):\n",
        "        \"\"\"See Schedule.value\"\"\"\n",
        "        fraction  = min(float(t) / self.schedule_timesteps, 1.0)\n",
        "        return self.initial_p + fraction * (self.final_p - self.initial_p)\n",
        "\n",
        "_str_to_activation = {\n",
        "    \"relu\": nn.ReLU(),\n",
        "    \"tanh\": nn.Tanh(),\n",
        "    \"leaky_relu\": nn.LeakyReLU(),\n",
        "    \"sigmoid\": nn.Sigmoid(),\n",
        "    \"selu\": nn.SELU(),\n",
        "    \"softplus\": nn.Softplus(),\n",
        "    \"identity\": nn.Identity(),\n",
        "}\n",
        "\n",
        "def build_mlp(\n",
        "    input_size: int,\n",
        "    output_size: int,\n",
        "    n_layers: int,\n",
        "    size: int,\n",
        "    activation = \"tanh\",\n",
        "    output_activation = \"identity\",\n",
        "):\n",
        "    \"\"\"\n",
        "    Builds a feedforward neural network\n",
        "\n",
        "    arguments:\n",
        "        input_placeholder: placeholder variable for the state (batch_size, input_size)\n",
        "        scope: variable scope of the network\n",
        "\n",
        "        n_layers: number of hidden layers\n",
        "        size: dimension of each hidden layer\n",
        "        activation: activation of each hidden layer\n",
        "\n",
        "        input_size: size of the input layer\n",
        "        output_size: size of the output layer\n",
        "        output_activation: activation of the output layer\n",
        "\n",
        "    returns:\n",
        "        output_placeholder: the result of a forward pass through the hidden layers + the output layer\n",
        "    \"\"\"\n",
        "    if isinstance(activation, str):\n",
        "        activation = _str_to_activation[activation]\n",
        "    if isinstance(output_activation, str):\n",
        "        output_activation = _str_to_activation[output_activation]\n",
        "    layers = []\n",
        "    in_size = input_size\n",
        "    for _ in range(n_layers):\n",
        "        layers.append(nn.Linear(in_size, size))\n",
        "        layers.append(activation)\n",
        "        in_size = size\n",
        "    layers.append(nn.Linear(in_size, output_size))\n",
        "    layers.append(output_activation)\n",
        "\n",
        "    mlp = nn.Sequential(*layers)\n",
        "    mlp.to(device)\n",
        "    return mlp"
      ],
      "metadata": {
        "id": "hSwdbGHR3G0L"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_critic(observation_shape: Tuple[int, ...], num_actions: int) -> nn.Module:\n",
        "        return build_mlp(\n",
        "            input_size=np.prod(observation_shape),\n",
        "            output_size=num_actions,\n",
        "            n_layers=2,\n",
        "            size=64,\n",
        "        )\n",
        "\n",
        "def make_optimizer(params: torch.nn.ParameterList) -> torch.optim.Optimizer:\n",
        "        return torch.optim.Adam(params, lr=1e-4)\n",
        "\n",
        "def make_lr_schedule(\n",
        "    optimizer: torch.optim.Optimizer,\n",
        ") -> torch.optim.lr_scheduler._LRScheduler:\n",
        "    return torch.optim.lr_scheduler.ConstantLR(optimizer, factor=1.0)\n",
        "\n",
        "def make_env(render: bool = False):\n",
        "    #LunarLander-v2\n",
        "    return RecordEpisodeStatistics(gym.make(\"CartPole-v1\", render_mode=\"rgb_array\" if render else None))\n",
        "\n",
        "agent_kwargs = {\n",
        "            \"make_critic\": make_critic,\n",
        "            \"make_optimizer\": make_optimizer,\n",
        "            \"make_lr_schedule\": make_lr_schedule,\n",
        "            \"discount\": 0.99,\n",
        "            \"target_update_period\": 1000,\n",
        "            \"clip_grad_norm\": None,\n",
        "            \"use_double_q\": False,\n",
        "        }\n",
        "\n",
        "total_steps = 100000\n",
        "\n",
        "config = {\"exploration_schedule\": LinearSchedule(total_steps, 0.1),\n",
        "          \"total_steps\": total_steps,\n",
        "          \"num_render_trajectories\": 3,\n",
        "          \"num_eval_trajectories\": 10,\n",
        "          \"log_interval\": 2000,\n",
        "          \"eval_interval\": 10000,\n",
        "          \"learning_starts\": 20000, #20000\n",
        "          \"batch_size\": 128,\n",
        "          \"make_env\": make_env,\n",
        "          \"agent_kwargs\": agent_kwargs}"
      ],
      "metadata": {
        "id": "QdZx6SdJzQ7v"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_training_loop(config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "id": "k28OxVrA-4pV",
        "outputId": "c397f871-c4ef-4b7e-db8c-f2a41fc03750"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|███▉      | 39991/100000 [02:03<02:59, 334.56it/s, eval_return=121, eval_ep_len=121, eval/return_std=11.5, eval/return_max=151, eval/return_min=105, eval/ep_len_std=11.5, eval/ep_len_max=151, eval/ep_len_min=105, critic_loss=0.212, q_values=17.5, target_values=17.5, grad_norm=1.52, epsilon=0.64, lr=0.0001]"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<video width=\"640\" height=\"480\" controls autoplay>\n",
              "  <source type=\"video/mp4\" src=\"data:video/mp4;base64,AAAAIGZ0eXBNNFYgAAACAE00ViBpc29taXNvMmF2YzEAAAAIZnJlZQAAP0dtZGF0AAACrgYF//+q\n",
              "3EXpvebZSLeWLNgg2SPu73gyNjQgLSBjb3JlIDE2MyByMzA2MCA1ZGI2YWE2IC0gSC4yNjQvTVBF\n",
              "Ry00IEFWQyBjb2RlYyAtIENvcHlsZWZ0IDIwMDMtMjAyMSAtIGh0dHA6Ly93d3cudmlkZW9sYW4u\n",
              "b3JnL3gyNjQuaHRtbCAtIG9wdGlvbnM6IGNhYmFjPTEgcmVmPTMgZGVibG9jaz0xOjA6MCBhbmFs\n",
              "eXNlPTB4MzoweDExMyBtZT1oZXggc3VibWU9NyBwc3k9MSBwc3lfcmQ9MS4wMDowLjAwIG1peGVk\n",
              "X3JlZj0xIG1lX3JhbmdlPTE2IGNocm9tYV9tZT0xIHRyZWxsaXM9MSA4eDhkY3Q9MSBjcW09MCBk\n",
              "ZWFkem9uZT0yMSwxMSBmYXN0X3Bza2lwPTEgY2hyb21hX3FwX29mZnNldD0tMiB0aHJlYWRzPTMg\n",
              "bG9va2FoZWFkX3RocmVhZHM9MSBzbGljZWRfdGhyZWFkcz0wIG5yPTAgZGVjaW1hdGU9MSBpbnRl\n",
              "cmxhY2VkPTAgYmx1cmF5X2NvbXBhdD0wIGNvbnN0cmFpbmVkX2ludHJhPTAgYmZyYW1lcz0zIGJf\n",
              "cHlyYW1pZD0yIGJfYWRhcHQ9MSBiX2JpYXM9MCBkaXJlY3Q9MSB3ZWlnaHRiPTEgb3Blbl9nb3A9\n",
              "MCB3ZWlnaHRwPTIga2V5aW50PTI1MCBrZXlpbnRfbWluPTI1IHNjZW5lY3V0PTQwIGludHJhX3Jl\n",
              "ZnJlc2g9MCByY19sb29rYWhlYWQ9NDAgcmM9Y3JmIG1idHJlZT0xIGNyZj0yMy4wIHFjb21wPTAu\n",
              "NjAgcXBtaW49MCBxcG1heD02OSBxcHN0ZXA9NCBpcF9yYXRpbz0xLjQwIGFxPTE6MS4wMACAAAAT\n",
              "l2WIhAAz//727L4FNf2f0JcRLMXaSnA+KqSAgHc0wAAAAwAAAwAABIRT+ionVsXUeAAAAwJaAI4D\n",
              "RB2hXRFxCBHCXN/hqKmMQFAEpmKy5k5bhbI/df/tqMACLHk4eINa1MHGhFr9xdpCqC9De3KgEYnN\n",
              "Bzy8tMxCHFm2sp4PLqmpOrQG8JlET1yxCqG6hIT8o568UXPx0rHP58dDQse/yrlpwHvdOxVwBM61\n",
              "r4o3A/nRcc1TEJI80aO6oRNSjbOYcZ1IQshqdkMP6dD6Jpihrb8N39KZm2rijiy+4YLXbe+iqdOe\n",
              "WQVp5mo0knMcMUhtMxHhnrKsgpss9MTMh1WhyR3N/p/pdJOqs20szuL5cx5HW83Z7+X8opazlp81\n",
              "luePEaLAoupi4D7tNuF3yKmQEv9rwvNSW0BxDMRqa0q79R1FJ8YY1cclpo3vs4J9uOzF6K49NE1W\n",
              "nAs1h0FOKNyk2/kvEz6tQ3fekXMcFVPzxiasxudziMi8f1x4kvL/tq9yG5194lwghthh9EDC6y/8\n",
              "icwe63iNpEsQgnhfFQAsFAs2hE3zH1KPjS/GglYPlmHs/oTgCMF8tj6EiKfisjjeBOBiOQtRHgSp\n",
              "Z5p0iVFFw8UbE37FqCKeiLGhPSYz7R/FovU6nMT0V8TCSgrKmoG6oCOyFXKmlX3ei9isPQ34FrYs\n",
              "WHa25CXOVZ+9YV5ehTUuKpba4emrGQ55IF1jehy4Pf3vNBRViVoXtFdBixhJAl3a24MrKtxeAEip\n",
              "DBfxl2n0lQOGuh/u8vm4MrsdgzrQr+7X666M7w/g7qT1n82KAU9n/kvQgxmFYLT1qYx26RkXEQqp\n",
              "Y3fQYueeOVRcfoIBsKMRe/TxBCtipbchkWujmT4PJ1jG2tDZ08WXv69iAZa0CMX+A72vjH8Uml59\n",
              "kYD+TJxCYqPO/v4O9x97BGePfNem/kZhEEWwJXXXu7WAOAVfAjVFUQxegvFeKtW7cgoHBnMg/3AS\n",
              "5bzgLzWw70jnJQmrewHAe9S3sIoyiRcdJJfdxv0ynFsgursfQUl4wH9HfOV8G2+Ir9RG6UAcqCDn\n",
              "atu7w/K3M7TOM2AAHusvIQkUFKpCxIMzTrOCW5iyn31YGoPlA46gV5fkZZEUc9g6H3mQ2iNjtTzb\n",
              "ZCwonykTQw9Hf9UlEONVwH2bfn89I33H6p8VY9APK7HPcBh9iwDltX3645RIDpS0ejvDesPvgzKa\n",
              "hMmXD9I+NwvbN/9Up49E0eyMY7Sm3S0uNEEnSaP7OIYlFn3Ng/roDSyU5PO7cgvSJkfceHAAAvua\n",
              "1fzs5oN8Aqh3SwB1fWehZFRWdKfT3zXKm7v8BxSC0xHD+S7aGc+UbQ10gA0VbExGoQfaV0x3/+N4\n",
              "FNrTcstppocN4pg8dUwd8JYBNNmoqyv5UElQsFfSgra7rnGUojvRFdoDZW8qcGNXPOTDkLq9Vypi\n",
              "kLjFFvRp9WbgRs/1IqRmLDl6WN2qCeWS7A71iRKWu3btjRJm6t2cKYqxKyADkEZsDRrdkNIppArY\n",
              "f9DWeqbn6M4eVHyjwyXQOkX/QVUOMvAV0sk8d43ECB/2soxstGAlY7vkMNrNJGiluoHSDjaVvwQV\n",
              "xdnZ72yXt4WlGIXljIIDygi8YukMnWUkLVAzjY7SLgP7OkluCn/t/wOi3brq03V05o1dnmbLrC5y\n",
              "d9zs8dxgaZyyFnJyVn5XZ7NqyPas/0/S15VmfkqggPQKOYWaDyX1xMbcfs1tW9UQHKpLn5IknCCf\n",
              "EVC+wdIwXClEb5/CHAHcKZSjqfRtCUFuwSdSmh/ymSUSpsOjzFaHaFVwkRdxD2DgP5/RqLiRMYGr\n",
              "mEPBLPrGaqtbzS+58eaaCOgj268KpttKToYMEAp97xKroH0aXukmoXyJRB4RoBlJe1+8UQB7P7TX\n",
              "mZ89I4cfbtLip0BIhy6a+O1oi7f7wHWNtnJv1cyatpGwmDOPxFwPABcUaTcGJYksa0SYWKInYTSQ\n",
              "QOX2siawLxNoTRKqmVH1IJXSpC4OKTALrCX8/fKHkAAUHNkeusyqVqsVS+V0QUOTPPG4Ds4EDoLh\n",
              "7XG0fZfTmV06sxpc8GiuK5KpXalzy+KjNRjFPgC/FagwESqaK3CXLMpNcsY/fx3s8ZvK1q9YHY93\n",
              "mGgLUVE4X9MeDejKpxj3QdjC9rhdQ2LosOwGEN+B5gWXkqQ9sJVOM9fiDqnzl5tZm5ZZzXW/uzQV\n",
              "eyZ0Tq/RUCwnrLZ9kC31u9XvBVxVnPC8vA91NdSB2mLSBUMZSbxq+q4dIJeM0sOKUphJR5NDNIu4\n",
              "LMo9j/eD8S2cjJmE103RvHcOjrrXIqgLZ/bKTrfpmiotNbiVER8WTYJwJSqCHqFQ902omwDq+GB/\n",
              "h81duKy6nJbaTZqJlYpK/B+y4Vm1jM8ats/ofMyXopN6N/9AI9eAd4t1AAAvYCJYA5Jj9FzGaLG6\n",
              "KK+UZla8tIRn3/7x0MK1jgtkG9AhRW4phKbRxWKfn3AUueFubggKpqzMtewuy6UrJINW5U8nNTt8\n",
              "Nixhi4XjWrsZ7CVoOXHrQ4m4108PZPoP5BzwXXQAcPINlGN5VlBOyYTmv/V4fQ3NN+/l0kQxR4Fy\n",
              "XPY3TpwNhDNS/MKhxhgZ4qdlx3cd4I8qLiPumtFPorcq0XPhY2ujbOQjL0ymqQZY4HdFMrUPgD4L\n",
              "MhsOXumKwygWetfr9cLPhEjT3b7dn+Xz1D1LYUuOIubzwW1rnMCouJNfI4qGzfXfKrGTMROON0YU\n",
              "YSYeimj0fBfCjRlJ6OpKiNddUAS4Sbj0q5kYv1uHRWxQK6Kqj7+Y8xpUsGd/PNPEG3GQwqswTgJi\n",
              "7wlP//yeVObgw5rsD/YAMD0pkMvZIAxMCd2Ga2/Lv6/Nn3Gocn75p6TPvuYO/JchoBnWR9DMEXw/\n",
              "Ukakq2wnjDvtgO5cPixuR0SuDJXOL3k2BEefDfrpUhKfb2u+NrNxnpcC6ANUqaZC0q9MKMbzVeO0\n",
              "EhJlyR7N8vhOVVwwdh8vFBa26u0s8JH5x0HA0LY0lGFxLje9GDnC4+X+QFUfW7i50MBDHFiSYiDU\n",
              "m94kkzy+bnA2U2miACxcB2EnpLibTCqUfVICRYMIOeJ26CypiT/NBPGCazb6LABYpmu10hh8/O97\n",
              "+CDdbwYJJgPtpcYQ5GDsRyEJq268ldLHTpvsQAHmpREJ+LSmHbojzn8auNP9KNtclGDvJ1IDG8Uz\n",
              "icAXI+fCJBKzgKbWOBm3DHgN42MdwbVoNumHECoa8FcGOy3s3HKc0XSgfZbQDDWsJHfg99Xzso4S\n",
              "yVkW5sUDg/nTD8EXy6Qi0Oy6rs+GqvBZts40c9aYMx13zNADcJnIVDFugqHm5Nrr8QuZ1Yx0iJCC\n",
              "Y6Z866vlzntZR/D31gEUeXqSCVLLu+use1qUQMAeY0Gdq1jX4tT3m8lWFa+N6OjHrXf33aSCsPkz\n",
              "aOVcxF8f1WDiWJfldCmkcxxaS1uSGeHlBeGkRgLv7ZPq7p2LRrKvxq42RJFbLafrUmzYteWf0jYC\n",
              "YOzAuJpMCjVXJv1AFXRmb/vEsgsXHvOcAK0wYBis6HB7Ig6eV9zXVxV1IpmlXRE77+m+1LAIK4/a\n",
              "jdxqx4/QZJf17CSaWZHdDU8yK6fa1MiKPxGIaWV/AEBTazIeOdjJq5PUmgoi/x00XTf+g7aAEnYo\n",
              "+YbVVVPqepZ/2Z5CQPAM4g6y8MlYivDx248oxs5PTkrjar0EKgGmbE9T+2TN+yvRssn0pYiij+o9\n",
              "KEvLFkW3kODhlV/+uB7Xx61ur8kgk47tewfN5eOC1BVFe+4VggjCMoU68WMBcCe6HayUfAmcj84A\n",
              "d7+nFz8U27mVDtuU897/r/r5D5jH/5/wLxQ4Vj/gljbVxmREuvrnpbg3jKXD2WVByd9as0fEefje\n",
              "gFW8lLrc2WCDt+XqBJ6D78NecFhAHInvxNHQjp8rqTKupu04gkvnHoe0ULyt8SC7TlHG2pwCmr3B\n",
              "E5cowm5JEs0I8c0tzSnGl/vSxjrkBZtF4m8tOhyMpsph5TE2zx0KnPyePhcVdTFy1c+BONpfrd6I\n",
              "CW+ITUwKoHx3W4/HF5oFjMhwUBEtp5b94Ojs8E3gQR5GU6moqHO1bzuWCErQf1FUIdZnl/lLtGSB\n",
              "CiaPWSuu1LaXl1Xk9R8d8gOai8kHtl1hBOvMv+FWuIdvD/oTfVwFwTC2D2c/il00zEaEnv2RypDD\n",
              "j6pgTBmivNmkYCgk8YH+ODApe5erSgI77aTeR+eS3U8Ft0zDtjNweAWWA4HrAQdB62m29go4a208\n",
              "yjaZOOrf/FU+gUVDoeapX5ysugnXxfCujMwMbXW56sR9+JVGCi4tGe6EVKb/b4cqPsTqpAH9ame5\n",
              "QQpF4hMpU0c2BGksPbYAvPnVJFjFvDgQ9Gga100NknobF3f1/8sw+mWMIuzKZhDGYTPZj7gRUN2f\n",
              "OOLXmkRvksyWp+H+i/+ya21B3ntgMFxFgPfgcs5X/UhgmDkALVylgUb6wjSr56KWvkhMX4ADKv5h\n",
              "xeOqraEMUGnWRteh6ED9XTOXE06bTDp5bjyBYv7J+aUBSbidMlDh7ZwGp63WwNpOMb2wM2YlTpwO\n",
              "AuK7VmNp/LsZp138P3vIJJ6ZbA0oBXNrlRsnBcJDY71ZausNP3qhaGx74XnIVfLPTUPyMO/Jx3Ff\n",
              "ZZCEg6TcbWG1kjwuI2/lmLt7y3ZJ+esBqPUfL90HHNZHA2mjOsdY9LXmksH2Bm1jTkWUS5nwbsGi\n",
              "Af+XALAkcyVPnOrzLvS38xUG6+kL0cN7p+R3UiBf51U2YSyIxMJkJyhmiedC5fDMt0opsQML/Jpq\n",
              "Hwplu/65Ma5iWcJ/O+U4frIF+T+FQcXO6y6IezolVMfKiu94OuttdI8kGks2xiz8yf8vg5ItBaLg\n",
              "8vtry9ZW05hWwxhIruW71zPAP7AfkWW7e6sGvBECJQs5kz7dQCmr3++B9W36kB7DYVKsIB/GH1Sj\n",
              "VB1mCGDHqtp4PKDxulrk+H38ew29Xj3/K8jfHnjQNwNsTZYiMf8dKPOOigUPezlwEtmF1sq55ood\n",
              "31CgaeqzeahYCGWB4NllkSiE0QNz7CWCa/qkPxHEScBOKkitYNTn4PTI86bxAXdMdTYj2IA3RSiq\n",
              "rTSwJRIxbptBk5SDieJHyU1QpjJviZgEA475u+l31x/YeyYlp3DKzFTZ7aV8nt9Bbr619+kBitws\n",
              "eM2rDDKmrQZY+DW2XYo4GCL3dV5vDhEW2ZKlYBPEHKkXvDfo7AoZwopVlBmfz8ZkJfq75C6kGbyW\n",
              "GiocLxrUfPjpwZ2NuqbZ4i5DxBeO8CkC5kQTemY4/OAMSZgQFqlc4TNXC8/Qj8eTkFhSTyvga+Aj\n",
              "emuQiJtNe+bTH0F+97yARODUTszhhLdxTvHZL8aMC0/DY1roeDYqUq3iYJP7ZJXQ3dADrH63/Jay\n",
              "7Fhrndfx8g88JS828axWBrHarUaoSS9BCEe3t35bSSGMAcPowDQqvSLk0QbvCjbHLYu4Hl8FqK84\n",
              "3QkER0PkTBITKmIP2gU0mN3oaIg7Lo/b29v2vzXL5baebAI4rVuRF5atS0fjqhYYGOPG5n8C+OKt\n",
              "yT61r3HDAMbOKLOMPD0DvrXHoDLpQ//neI+Z3obXnDNwMzeLZdtU7iP9ajcecxGS7Q1UAuepIxb9\n",
              "Q5iKC9Z1iny6adu718B8U2uZrwLCfJM8hxh15khWkCiVnS1O6B/nGmClohSK5FgmiH0EKdWb3Yxb\n",
              "3mVd65ro+ej6L/SdEDDNJC9xxsSyXQa0wr+zgNKunN+WcEXhZn9OHpBEhUs7bQikw/+/0w0WNz/B\n",
              "/tmwa09lrBOL1NLlaS0XUSUY2qu30kZK0pmFeFT1a/YuBkSiMf9wcp+hFKmZB86rrhuVFmHYPHWw\n",
              "UmYRncF7SDYdn/oEIc3OziylFHBPcBriwzu7C9CFxO9WUwgoXewyiKlfyOqDfufqZQ8+/vqTiFzt\n",
              "X81lbZBbHBPKUxQiM+8hSKUN8KqLn0zlRAx7gOtEU60eZi1wEGslgEpPEIFJ+FJgVGLJLbCli54k\n",
              "s3X2ATHiRb6kr2gIGnDVHPj82It/x5T3J5QPto607W+pMd8JZ4LrKL96W2LG0NJJ8n23ZFAa5u/9\n",
              "xbAASo7st3+bUBrV/xZwgwSJs/bYFTVOag9q1L95NYyX+uN6KQBlwoQ3EKKdOde1BC1WK8y2Yblz\n",
              "qFI3wEOBqBpXTXSU3CzOIeJIqDOq+G9hHIpRUdSrYSrEcKpIYV0+oiO/vSt5f4erUbWxBOpViwpv\n",
              "BCgblipiPTGDRToxy9xM9fny0eNfQuFIpvkhjc6z9m7lB2odHsQUrkOfdIwLtqbse5MYcdcYldJo\n",
              "TOlWaIKYghfIWYpRhRKbG11bod/XlmPnoBaYt3xflnu0JjUVsEVtL6QNipMd9VDFX/WMl3G1uniE\n",
              "/y52lEL3kAaxrMDCBMRSl2zwy1AU0tjVJEKVB4nrcAWKWa0YQ3y2c2yMUDRpiDYAbCZXh6JIlWH/\n",
              "FF7zYuDNuY+y1bAiLQx/doAMgv46tI+LUMzYXixqtURCUsnXydwLzAZs5rBeT6spIqNk/4FFK7pA\n",
              "LF22vlfebVSVJhqucG8KanBqNDvRIwGFOqXZBBDaho6+T4entB7vZKtnBJsKJVY0dmEFTbuu+vKe\n",
              "6ziQfOx3qqKwft2leDqA4IqTgbiwMX1XGFpmfRa/IpdfhUoG4zkQAAADAAADAAADAAADAAADAAa1\n",
              "AAAA20GaJGxDP/6eEAAALoCNcAfFX8+azw59unegJq4Ui6TrWj2ydcpmhyRcYkXS5t42nYCxUj4j\n",
              "TfIP1HCo4Fm2phbdw/HeZY7oiWn8aBIUwqHsev1sC2f6vinNRG0ZwuMS08VvrWyeffxrp18wSOXt\n",
              "Ua6ClmWs8TXOcpcoRzO0+Vf9IBi6g0U+MVkumV1o2L9KFwWWo7Uw+tcPMEBQFPE1cjkF3eyNeFT7\n",
              "b8IZ3KjbKrr4+Dj0N4qq/vfwzdpGKZPmYcYeowZH0h/yCkaXaFg4smfP4IVyxTQGWgAEPAAAAC9B\n",
              "nkJ4hP8AAAyQqGwpnEtjxzK+VuzkIxmqfiWixwRh5eJbQqL2eroqvwtwG4AEjQAAACABnmF0Qj8A\n",
              "AA7WWDfPILU5Va1h78H89va0GfkcYAAB6QAAAC4BnmNqQj8AAATXkPAmM9dP+OsFTKU9W9poJ5YS\n",
              "6CwALhA3VHFyps/WgygAAGZBAAAA00GaaEmoQWiZTAhn//6eEAAAD4FGDPw3z7LLciEzhlS/dgyC\n",
              "6xoJiqAF418yFInRKnvB1ppucRDNjf53BfRxKRDFh/Gj3eR/nZ4kaql9ppy1FsbXQPdwGn9qx2/G\n",
              "0WrGfll+CW3C76K0ghtwR/E2+KR+W9U8+oIfd231jB6qHd6AUvz63uKRuIG9iY/jLjR08zUdGuW8\n",
              "dkC1urFnEOEGwmkfwR8QfNIVPqNkJ6u9eyf9j4PWJbCZN/iKZsfXzrjUGNxG8O6EYLtjUXeKAkZZ\n",
              "zAAAFTEAAAAxQZ6GRREsJ/8AAAMD+A0hBGTfZI6wkKhFEDp88XVOvsOoUNACT1rF6leloRiQsAAt\n",
              "oQAAACQBnqV0Qj8AAATVejXVPaHXWXoWnDD+ioUQSMiegXt1zEAAB80AAAAYAZ6nakI/AAADABNY\n",
              "E9LkoYZrC+aiDIIeAAAAdUGarEmoQWyZTAhn//6eEAAAAwDcqRUACO3vpwDHSByf1MdPkN4swRf2\n",
              "C++4heMzBDdG4p4MjJ4kP6r9MnmWlkTQtps7Rvd2lLRgherWhokM6fDCS5YIh4JhJYq+DywTSCIF\n",
              "//yLNUZgbbFpIxeWxU9pFsAr4AAAAC9BnspFFSwn/wAAAwA6r8MDmhGfIgBR1JgftHBfyutoJDga\n",
              "ZKkSyPXx1zBqUgACNwAAAB8Bnul0Qj8AAAMAR4HAWlO7YrEP9aZ6rxIhhFWAAA/IAAAAHAGe62pC\n",
              "PwAAAwATXlgCwozykK2PDqDFEZ4twd0AAACDQZrwSahBbJlMCGf//p4QAAADAKhBtaBdAIR7nPTd\n",
              "py0dsh6kXsuEQk5jRKh+5uuKbDlYTnk0DHyh3yqyE/LH2cruZt5YEHqfZmw0dp8Nwe5gqxMqiMjy\n",
              "PVCu6qjheMoQc05njLtpHFbjK9vyIOQIpo1zyDtL3+CF/44DWy50Pl5AMCEAAAAtQZ8ORRUsJ/8A\n",
              "AAMAILuC+v9U1BNCP16hj4WjuSWVzhABsfd3To5sc+kcAA2ZAAAAHAGfLXRCPwAAAwA1/1ral6En\n",
              "mjOf5Sgl4iPAAysAAAAnAZ8vakI/AAADACj4h6Missqs/pUYz6cEICTRkABxb4f3Us7ZAHHAAAAA\n",
              "k0GbNEmoQWyZTAhn//6eEAAAAwDcrGDwAar/+ffQGr6C034pv0VIB1RHAv7TbuvOEloD27QgDl4Z\n",
              "4j9n/Ycx+8UzHlebus85/zqGE18PCF6ouxwxL+Zmn0L737t8Hfs/G5OIvY4CnLqF+E878FxF6R38\n",
              "lnKACaek03XkeTPs+lfNRQZzxchSY/GekxQmifQF5AAs4AAAADpBn1JFFSwn/wAAAwA7YTE/fUsK\n",
              "vHwd3KyJsOOCxVhIKMdQ+qzLzvcxAAE6YSCd+V6F+fra3UOAAI+BAAAAHgGfcXRCPwAAAwAo/HiS\n",
              "hkB6kTyjNAqu7kBjb7wbMAAAACABn3NqQj8AAAMAJ9ikPUzbBnV5GEQ3OC1r+hNDdYAdMAAAAKNB\n",
              "m3hJqEFsmUwIZ//+nhAAAAMA3afxhKAPgzOO4RDJ8GFX0Mu+7W0hTi4fr39nCeR7ukYfO4NN2MHO\n",
              "Ony2GkuBFzRgBVfel2jhCDo0YG58aKoPW8blcE2Gvq59NwujEWfxr9pxD6xb9JJ+qmrfxrTfZm0H\n",
              "syDd+l/nHwdkPS6S+IrFvB7rX+TfbjzS6PEukt3CD1hAYBvIsQUbBbzDFb8PBgEzAAAAUUGflkUV\n",
              "LCf/AAADACG/QjBzYqWzc2cpiRGvPIAawHQLu1CW1VU/HOXLj6Z/mIge//Md+BIC9X/5KreW1j/q\n",
              "cELJO/oq6ZpEBQz5/pnbwAAGzAAAADABn7V0Qj8AAAMAR3SJyAIiHo2edH42TKlrNeom6bTwVZoU\n",
              "ZW9pFPPP2GT5UDPgAUkAAAApAZ+3akI/AAADACfYqYHTSh54GOPodlGFCTzZABuonTNHMKoF7XAA\n",
              "O6EAAAB+QZu8SahBbJlMCGf//p4QAAADANyNWsxeAy7gAByStarEToBMrxYOaLmAIXoD6RP7CS08\n",
              "5bkhZRVZuoGwm9ozStBjAwOwtJ/g/jwR2EwPcg2mk8Y7uzFgcUXLy43NHW0m8soLk6QFVDwOSTFn\n",
              "YSSTYb4upFzcysfdW2NAGgFxAAAAS0Gf2kUVLCf/AAADADtTeuiNMwABxMACzxv8aelcmcjHdTNy\n",
              "DWsbOcn+FIKdAg/NIm4ltRt+nsjLd9FPaEaDtnldmtBT7nmmSQAJmQAAACYBn/l0Qj8AAAMARnsV\n",
              "PYFFqoUw9rxUkk7TV2A5UbiCkT04eAAiYAAAACIBn/tqQj8AAAMAKPED8WcMaHq1RdHQell1FB8V\n",
              "XwjMABSRAAAApkGb4EmoQWyZTAhn//6eEAAAAwDcirN5aFzCuPiAQ7wwFQ77fbIeU9b1OYwUmIFy\n",
              "10kLnGs0uhf7DOJ9HrUSSFAPygmxBzS5owls7JbSgPvKkgeu5tkhxHoisF4b/os7fLeQsLdqjQi8\n",
              "oxgegFxCF6hgshBCdvZmjy/fdIILpMXYhKbBV7uPoItxzFEmpRysQcNz57OMBCjMW5No+EARWuIf\n",
              "/8BgGVEAAABtQZ4eRRUsJ/8AAAMALXP3InqmzoACMAFJWH4MTZpWHASBViV189P1/HUWbeGfGxRf\n",
              "7Ia44ws4Rkm17iI6RcPkmaNlRj7jGKzVxqtSqJj+cSzSi//vh0cSyAiPW7R+MbQHotL3WnqQXwIU\n",
              "KABDwAAAACcBnj10Qj8AAAMAJ9FpBU5L+DapuvFOsh7+lVxyAYMxltmV54gADPgAAAAwAZ4/akI/\n",
              "AAADAEdPVfRwpJBtPHLx4NnP1Zfyv3I8nu7YNSem7bFbpdQo4zOAACbhAAAAp0GaJEmoQWyZTAhn\n",
              "//6eEAAAAwDdvTj22ZAIylGkqM6ygJAMa8X5nk3RxcN9bB+AJ2IN+sPubtQtW17Bs2JVWMsoW8cw\n",
              "xshUOJuP5SxK7JbX7jIHqQ7lzr+lcr7CIH9GSsjI/KkyBiiB1qzKwjoMpP6/xK6jidjqcJ//7gyq\n",
              "h3kQWP1OZizANP7r9OrvpPFtASZ/Bp4WIUBenn4s1hNbyOzIQTsnygR8AAAAUkGeQkUVLCf/AAAD\n",
              "ADtsIkQAgB20pTl2KVQhMFYElcPjNRrv8PIn+8hyjLn4Dw+UZUnrAYtILwVwEZEg8KrtcfDSM49w\n",
              "UEblTuFGgHZNE/2AB3UAAAA1AZ5hdEI/AAADADQ+5Nqxz67TV0H+kC6WQcjw+MzDeM5Pn+VPLzlT\n",
              "IBmUqs32+iWTTGAAm4AAAAAvAZ5jakI/AAADADQ+5NCY8THceazfM1YOSIJIMQJN/psiSsBlF+yq\n",
              "sKrRmPAAdMEAAACiQZpoSahBbJlMCGf//p4QAAADANza8ULqAL2fMEqcGfcAB8RnF4eUqKDn4fg8\n",
              "n/UbGScdvRU0rB6FPkCwaJH+CWhrfXuGfaPFiwhGXmURQuADTwZ/NpkEqSZb/LObEkaIEB+/11QX\n",
              "S8lq7r0834Y3AxNoWN6yjBPVkOf9acQYIsN/mfWclvA4KNywI69Jb5c+s67XJsvfx99ShPhy7dUM\n",
              "34GzAAAAVkGehkUVLCf/AAADADtzcspyfWwUG0ejKAAGrcxn1eYlTEzUkNNMjCoj3wqradRdhW0/\n",
              "0iaRR2RwJvJWZrl8bEwCQmqjuoAPQsYOSl9gRuMF71VoAJmBAAAANAGepXRCPwAAAwBHWA1psAMp\n",
              "hzMDNmr8XU1xmzLLQE0kcODzrcFK2xUjMWCsLuszamwAARcAAAAvAZ6nakI/AAADACjv6pIk8zxN\n",
              "lAeNEOPG/Z2hfQSDANCtaw9Eh1FbqoaSM9WAAtoAAADPQZqsSahBbJlMCGf//p4QAAADAN07Xyx2\n",
              "ALxJlBpnracW4c/HkEmkT2nfzukZ1OlCDV9erWtGf5/PIMaLIq7awCzs4CFoCrssNR5v3vr1K7JX\n",
              "ywfOZHlcigPp9oHrM4VQ7DPWToGWmY0fyAIHcnFbJ5a0hOHiJne9UA2oEnV7b9PootJ2aH/zSKyM\n",
              "7UsGW1Xmel3qnekvuRCGUbziJ65uYm/4JOt4bbj921fepPdsPhr69x3/5wOxO5qYdPPGY3a4qLsC\n",
              "nuKaaS6tG74cGgj4AAAAWEGeykUVLCf/AAADADtuXuwA++TbRyEvJfLV5uFEF2dKIggVJB1F29wl\n",
              "KiaNKkx1FmO34L3qgICwYVFoouLYuMN2h+fwdEvp2S9VkZYq5sCbn+MSfdgAMqEAAAAuAZ7pdEI/\n",
              "AAADAEdqJ4a6k5a1Sq0B/PeapCUghgQy/yTO45bLQS+CP3usDgAIWAAAADIBnutqQj8AAAMANNJZ\n",
              "V4B9aD91NiZYAd+ruZI7yftQDTE8m9Flt0AF3uljx9aRvgAEXAAAAL5BmvBJqEFsmUwIZ//+nhAA\n",
              "AAMA3LIRxwBU/5aJDACEQ1YL7l+X7a/BAjEYj0ev+Aavh/CoDGAmVsgScCevYyWoWQxkZ9430nl6\n",
              "3y3Yx6L5n/5DkpXWNvQxJBotNQV6y+7w8I/2M6WwpKOj/Rxv7RYZ5O60fHMriibci55VHhDN4pAQ\n",
              "mp8/05RPz61NC+aGiguKBWT6A84UoH534gbTpY3oakA5fWBMvuZCticBWAM7SQJPU4Hd+MfipJ3o\n",
              "RwGBAAAAVEGfDkUVLCf/AAADADlkU9nJO5QNAu+NZ5k3ExpemgbKwEQAtfy9UBQzTJVoaFYwfOiP\n",
              "N8mCdYwSI0LMqzEgX6h3migQSDxCCtLlHsY1/pYm9OADuwAAADIBny10Qj8AAAMARVgSrbwbeDJL\n",
              "3BdxYKLoVLyjB+RYbQT2ASmTr9TaHnx0zzmRzKgDFwAAADMBny9qQj8AAAMANhs0Q8+gcEw6bgrY\n",
              "mpHCqUjGbMLwsDMzsVpciD+uMqWKT0d2a3EADugAAAClQZs0SahBbJlMCGf//p4QAAADANza1jfN\n",
              "RkdjNkLIQCPFyHkeXHEtFuuag5zTKR8c7Rq3ZlStCJGo9/vVy9h5kjG5fzTMC9M/77ta2WENVv7K\n",
              "IdBxeVzQntBRsX+4q4fApJtttN5Nin8MJqhfWxSwB17bdvwdnT1YG15zJv88xQpc5RTi1AMZ97bi\n",
              "A4URYaCBoExn2A4NYe06ZsDt9uGRKNysgOmAAAAAVkGfUkUVLCf/AAADADtt5kAAgpJQzwGMUqrK\n",
              "fGNklgpsvFs+to1X8j+rrhiok/lLbSH/EH9D3YfOMYwXgqDr6qOiWinGXJ5FxRV6aB+jrbT9/vXO\n",
              "oAmZAAAALgGfcXRCPwAAAwA19uPIyTfUyFu8QDfXH/Vf3HJJ+cUmTJuC/cE+pjlYj4AAEbAAAABF\n",
              "AZ9zakI/AAADAEVPVpFWeK9IADiYAL+IIgMn0zcXY+BQNrtqOOMJoU1D4lg/mAZEATbTu15Cd1zW\n",
              "ec84tvb/9mbwABvQAAAAtkGbeEmoQWyZTAhn//6eEAAAAwDcsI84AYvog5YCA0ht299e6nVxSry5\n",
              "VQ72D3brGu4fBmISfmLtjcbYUgM9TQVIrzbfC4JH3u9OX069mpvlOvfVXj7ZUBHlaFmzWFCDH0aP\n",
              "dgMW2r0lzA4ICWP2KwmXtq4KNhjekiKDKzuBmKBqF1gvGgdfJmrgcC8Bp3aNZeCoLa138wPjFa60\n",
              "ckl9DpTNsGpCsgZCqyaFlU/zHCrJH8PVAA/xAAAASEGflkUVLCf/AAADADtzVayYrlSuI3dot9gd\n",
              "d5r1jLW77taKgsZAPnZ+ES60dNQlvOf8fQY9FvRMXWubhnMprTriLikEjEAZUAAAADgBn7V0Qj8A\n",
              "AAMAR2oJAtO9tjZZcN4Peaig9vaAFrcwGkzVswEBkPaRn3zdXHmYVtL7qJMmgABnwQAAADQBn7dq\n",
              "Qj8AAAMAR3RGfcFAe69CaA/KQAHG0z6+ojkFY69cEj6zp8Vo5qD8y1Bjua4AAO6BAAAAk0GbvEmo\n",
              "QWyZTAhn//6eEAAAAwDd8JzvpdJ9QBbC7pLu4uwUsCAsQ6nitT0cv2YUuV0m0PEtvM2+97DWnHiG\n",
              "5j9vUpq4JErHkmtc/J/KQBzvcc7o2S6UbdxCZQQ2EdYSS9uG4p1U+ow+UUT9lVv8Vp8MJgFwkyFo\n",
              "51p8PJNkhctwo4SS04oEVkdAByMBn5OaAUB8wAAAAFRBn9pFFSwn/wAAAwA7VupPDkbnMZ1sL0N2\n",
              "nqAzezebz7a/0n0Cu+w09AasaXWJsUiL2SeTF35STs45ls/mUipEphxoHRVtP6xysxQGCzmphL4w\n",
              "AXcAAAA2AZ/5dEI/AAADAEdMWRfsSrdklYMgDTFlQi/1cPyzfXk/EerACHsQdW0OJrOqktsHLMKG\n",
              "AA9YAAAAMQGf+2pCPwAAAwA02zRDpWbejiL9qq9UdT1SdNjGR8DTRPaFbtaSxFiJMjH435bsARcA\n",
              "AACpQZvgSahBbJlMCGf//p4QAAADANfalaXxAG+nMBGi19hbi9s/Dti+5Vc1KxSE/CY90ck55oTw\n",
              "ypEi0IhvJm4ra4T590O2P+iXvbtPMvDjP+AGFaFEF1IiEEa34ziMvrk9LHv6cgueFQbBlzXrAZAI\n",
              "mOl7NHUTClgx1fQP/HWQbKtFwQc+yUkFa0B2ig9kJz/E1FjoDP2K1sRzNYE2T89IYZ9ECUOkm4wB\n",
              "MwAAAFRBnh5FFSwn/wAAAwA7bwZj/HeEyX2gCOiiMdK6OEWO8fFNuhwoJFGLx7b2j+yujj2+INti\n",
              "eq9K/++QB5NfqK4vKNQTC/ObtHbvTNyesYl8Dn4QAoIAAAA1AZ49dEI/AAADADV/ek0te3BtD+9L\n",
              "i79mrNXdGFjQnAAEPx7l5acAHNi/98sSC7lUvUYAMWAAAABCAZ4/akI/AAADAEV3spJYGGpa2GwG\n",
              "coAaICjV7IPNsO1MH4nI/LTjw8xrTj6Z9wSF8eA7Wn1ZuoVII+lLMcOUAFBBAAAApUGaJEmoQWyZ\n",
              "TAhn//6eEAAAAwDYT0rTsQBw+ffm2r+gctJCZxH85nIUB6DUzYCv/9Nynza5hpMoL/QDVu1k0jcX\n",
              "W4E60t6+p9lHdtN3hmQR0fH3NmF/ALqtQZELbM7yLTEVAblS2IaRt/H2wk2HWTyqxMXjIB91XPtX\n",
              "QmlXdLbg9wRN8OqD5Ji+326kB4+1/XKQpKRJje4GQCIGhG14wobDgMDegAAAAE5BnkJFFSwn/wAA\n",
              "AwA6FxSrKC3IozNh2gAjKAD0KNe6WWX8AH4mColjuvba8YQxAjWd3yhdeh76lLK9qk0YaLJkMB+H\n",
              "zwDnhslfnuAAGBEAAAA0AZ5hdEI/AAADAEVp7kTnT98c1ZDvheUc7PuwGEWlQ3R91FnnkkzcmeQb\n",
              "8C7cNfleX4AXcAAAAC0BnmNqQj8AAAMARYlPBUrZxvX2kbWOLMyLEYSw4gJEwahsmSq3za3+2oQA\n",
              "ZUEAAACzQZpoSahBbJlMCGf//p4QAAADANgAW05huvxZYAHGf9Q3GiDgIyMFMHMPzS5n8say3APR\n",
              "3iVQH2vMk8QuUSfjr2/e6gaZpjOXtF8hc40pdq9/56arZXE9Wv5p/mIWCVOnTRrkOTocOOxw4zCJ\n",
              "UUKapIReH+2kDlJRW0yXxKyxQHrEyOl3DS4L/FOfzl9Zqbsl8yyUWMu8KXnOLx7uGdgdyQaBEtBV\n",
              "7s6ImbN7xSSlSGBeDjkAAABgQZ6GRRUsJ/8AAAMAOfzmBaAI5ffg/DbpHJc4ybtNhXoSb5g3HWsS\n",
              "t+P5KZoICgy679Fd0Mtk4ojWHcXfcftsC08YNKf4dkDP9KYPNdsJqUKyCSdeM9LmbPHZM+qsQAMD\n",
              "AAAARAGepXRCPwAAAwBGlFTXvk2CUnNqTJAC0QMpt6xImstQ0RcDtc9np9pODhXeMl5N/qaitaXi\n",
              "CX921Cgy4RTM0nbgAEfBAAAAPgGep2pCPwAAAwBGlFFwSMdSeeP84nAAIGlLLFjK42vIyO18y9gG\n",
              "4k5xs6F5jzKGktvwPQkOA6tskYMqVgLiAAAArUGarEmoQWyZTAhn//6eEAAAAwDYfbJg3SUARINq\n",
              "G7IAnJAIqQgoO70Vv/kBeklhMDQEJKEKR0SACbjFNjZ88Dq7e5ZyreTlWd0QQ8eTlj2FEVqQHC6U\n",
              "RxoE97pCvKyvtiW6R6o1u+3DaDeOV+FbZh6u6HRKKv6ARV5UTPFPjJ7o3USlM6c5PPBs8ZR2u8QZ\n",
              "IuK4ZceQUzqHdHoHbqQYiAsogTPI1Jln5BEMYHpAAAAAYEGeykUVLCf/AAADADoTONvoACkKoyTN\n",
              "Ioas3ag7Q7oWUBQYs0CSBZmwFMqVxco5CsPS2EKiWil4kBrg/ioQ7+cGFC0qYmfHtVswpgvNf4Vp\n",
              "sW7KtcaGSBHdxTA4hABUwQAAADwBnul0Qj8AAAMARX6E6MsbhGoOJ4H/MSMaEWAADZlDVHCdcLSk\n",
              "HlPmlAFgX0Yf5Vb3GzjD9KC9PtoA44AAAAA3AZ7rakI/AAADADTBUcgwa4b2n7c6Y8FhvqgDeuR/\n",
              "7XuxwuUG9ABfGAELweFKoz+WVTtStABNwAAAAKlBmvBJqEFsmUwIZ//+nhAAAAMA19qonoAClaSZ\n",
              "/7ZjV9dDaHxxTP0zd5TU3wmzMFlCyyvYBWEZK2Rp4SvO9ZguFfDQicLN4ufLGupHuIyKoZBheudo\n",
              "RY4xFH/NapDL8MYfo+saVmtrlpLWeUTbM868boOeiBfITdGd9LnAdhEY8K/U/srv9dLfDqJQah4u\n",
              "iDt1A3Xq29FiHjcLNmrI+topI+bdhs5kBYHpAAAATEGfDkUVLCf/AAADADoXFI5C0j3Ik0FrQtlU\n",
              "RIyXjGmlbFsFtjf2QAEFvacsCBRiVUZibhipmh6syn/BR1xgEFD64lIFTGgLrCQAfMEAAABSAZ8t\n",
              "dEI/AAADADTV2KQA4MvVXmCxJJHWsRg1fGWHEqucwYAaIS6EA7gdRTv+UpKpydnRHmbeEjytHSuB\n",
              "KXnJaLWttPc9s46HLalTwRlewEADjwAAADgBny9qQj8AAAMARXerZb5hyxBddMorQD4IAM2LfLjk\n",
              "HyknW+uahSY4lNPbN6fUG7RytxM6MAAj4AAAAMRBmzRJqEFsmUwIZ//+nhAAAAMA1623dAAVxSpB\n",
              "FmvDe+9gyON4Cy4T+VJ5qzzrpxujdq5qawQydRgOlo2l/m7RueCjsylrE3sw8+lGhipDeqWhcpIi\n",
              "p8FFr2Dhk2/nUpeGEgJkfQottx+u8R1qdK81qed0LZDm53H1g8IQoAb+CRiTBVgn0+5wdpFx+b/1\n",
              "qWNh1gtu2zjDhEKIRrjINFe+hmXaVxtQoGnlc8L1enWZtqCxvjPKOiv+KhdVFShJRichwKaAAAAA\n",
              "WEGfUkUVLCf/AAADADtgvKUZ2zRc1L2sf3WMtrYf96g8Qc3BbRSLM1lhABYAvlf0jbWrOBXm1JFe\n",
              "Pzkf1C+i0WiVoHoV1Xo9a6js2O1iwFnzoi/7fFGwAWUAAAA2AZ9xdEI/AAADAEVVic3TqZFoF+/a\n",
              "ERhsI2EnOfWGoVBZS0qI7c1fPxN8yha8Noyi+AkRABTQAAAAOAGfc2pCPwAAAwBFdscmm+PaA94W\n",
              "5JtJvnmbAc4LOGsDq+M03RKsfsUYQ4K9lb2FcmXtVwzUADZgAAAAzEGbeEmoQWyZTAhn//6eEAAA\n",
              "AwDXrdsPQscSARk2sv/CNuw9TOYGNVanyfv/pr/iVmp+tutUF4jXLXO/ebgOIIjGAgrz3MIzyzwf\n",
              "v03bFO49HF75+ap7Dd6TVGVt4pMOoP4s2YY0tVMpuS1LvNByrBz8ou7njLj0lmMwWacra5Z65Y/3\n",
              "rLY1hibCeEWfILsUEsNW3DWHCKa0ZBINstNkydpketIEfTHCT3vNlOwmh73ys6UeelAUuxEPGQn4\n",
              "W3X+wzhV8jz4YIZfy5gh4QAAAFVBn5ZFFSwn/wAAAwA5/H0Ei3yhgHKZRwgCs4SCdn6aUDpXKB3M\n",
              "OHsmwAlKa5M0imGkMLVfcT8mFL+gygtI9wlWO2wUEO58+LF8aFfQg2Pq4BawANGAAAAAMwGftXRC\n",
              "PwAAAwBFfKjbSbPc5ebMZ1vpLW0m4zoyfSCpLJ3+w75qxPmuvr+KcAuXjDABgwAAADIBn7dqQj8A\n",
              "AAMARYkaKB4VTWGr6JBA+cxA3MB6mqs9WWaxvl+3wWKK66ZNA08nGABoQQAAAK5Bm7xJqEFsmUwI\n",
              "Z//+nhAAAAMA2P5HM7TKXCA1CBAO7fx6Ul+waEBMV+o25Mt2QJ2iUhcbS4FnyjKRwZI/gJGyaVME\n",
              "3YUE4dWvv9mjlilTp0RB1/4hEBMOUvqFCFmT0cEEZZS6MmayfyuDv52N3iqKILUAO7DK9yO4ZALu\n",
              "8CQbgkr74tKUNWylbIfNi9dTOn0LYdNXGx8mf9eQ32hzKqixsFZ24r16TLVnLtLAf4AAAABKQZ/a\n",
              "RRUsJ/8AAAMAOgK8hF7v59ZBh3rdq6B+769Hk1coalo6bociSUdEvxBOqQVFITyjcDOU7n80S5cU\n",
              "vUnkqJRRpknsf7OoAQsAAAA3AZ/5dEI/AAADAENU2ijKvH2RzUpYSM39HUCk2whKk3r2DwMqL7X0\n",
              "4fiCdaMXR2nI/sIuYgAGVAAAAD4Bn/tqQj8AAAMARV/8x53zUEqyczwW8lsahACsHWA/I3DVmaL8\n",
              "be11R6LUI5qqoLM8rFbA/z6+NqJbcQADKwAAAMVBm+BJqEFsmUwIZ//+nhAAAAMA0s9sElKALtOD\n",
              "3i2XvFO7Q7LudSgHGvT79RyklmF5E2F/WsY4LLotz5XCtN5vBiJ4AZJ2EwpzXZe9EBObjsLPBYEW\n",
              "B1HdXixpIJ0rrvrtONT9p2yFbsHNuLT32VCRN1P7hQDGTghg/lWiPyz4Ca4HL8j+nn4gRAU3cFdR\n",
              "3Q7AQXtBTTmSrOYeg/bggV8sJ1tDEl/QklsBNg5h/MzI6Uz88h5b6N9vLHYpQSDdn7yBo40DlwAA\n",
              "ADtBnh5FFSwn/wAAAwA4rYXEsNgCtgb4hauAye5IEvfz5cFuaDUvcOGgUrrd1qAD8MzrQTI1H6f8\n",
              "7gAQcAAAADEBnj10Qj8AAAMAQ1WUMQOY8LfVH3frOVf3r9nbnlFjW4/NrWnqQAqfS5foimXKAAPm\n",
              "AAAAMgGeP2pCPwAAAwBDWt5KPWoSPTZN7/lOyOkBIj8doMwZwYqtY0YyucGKkQHS2bDEACHhAAAA\n",
              "yUGaJEmoQWyZTAhn//6eEAAAAwDSrlGXoAVnwom/INwtchkjW/e7flzhegbsu90bT62XLe06NWBF\n",
              "BpPVmnGGcrnCXSibwlsQMLPEmIQ5YoNjwakdbzWVwFzulFo79ukhvCj0C+aZ7q3xvGJ88bTMSEav\n",
              "EDJLWSDvvU2NjMstm3BeM01vA1PE1ZSFk6pw6AHOuTC78pLesIPEINEUZSj3Ejv5c9z/Wn5VFNtI\n",
              "stHNDBYSf7aejwkaGRa8KRdVssVJZaMI4yhSXXgJOAAAAEdBnkJFFSwn/wAAAwA4rWkaF4hTNKAG\n",
              "zATJNnlqtzM88wwLkEuG1+WpOwVX/Vk13oCfrqTacNAPETA8LgnNXLAS8N5iMADegQAAADgBnmF0\n",
              "Qj8AAAMAQ3zREoAVgKXg95248PTnQvllK8QxepMXehzN/4k1gcv8WmhmKm7Jt+Tgg6ABBwAAAD0B\n",
              "nmNqQj8AAAMAQ1o4O1AYQA0BHlxTsnrKfFuZMmORQ2R1Yvda2EoJtn8Ng2JFppUrVVGzauvinu5I\n",
              "AFfBAAAAyEGaaEmoQWyZTAhn//6eEAAAAwDSrlIQAAWJCgG5KjcmCvqnFDRCuY/pvQAb6fKa9FFQ\n",
              "W+6rlLkjl6hzYwiFKnxEc8motx6cIMiOhdz8nvj1rc00CPNaWWaa40rGPcCNSuDukJPPY+hRmhCS\n",
              "NqnoWipR9FHca9LVxzL7Auiv4k2HCYM27/gQST2ZyRKw71h+WyfwXNE1IW+GSJ/fhQ+aRdfEZQFV\n",
              "g+zVPUAqSLy/BJtKsxpjJmuRRIITO+VOZX9xLOwJ+xfcGgz5AAAAPUGehkUVLCf/AAADADib80ne\n",
              "SYpSTIIIM8FaQDEu6suqVdezAMsUt0Lli6LN6BwvGX9IR0AsxZ9PiTgAUkEAAAA4AZ6ldEI/AAAD\n",
              "AENI5+VH5xEDxYncHqkhvlJfgujBXGp5L0ywA2veQXpxxHDasc6ciQR44oIAHrEAAAApAZ6nakI/\n",
              "AAADAENaOCCzSn/NTQZVH2WWK3zpcCzC+zWWmJte7GWwDFgAAAB7QZqsSahBbJlMCGf//p4QAAAD\n",
              "ANOQXY0TTAPYAS+jWtSedJRA2s2atbO8dH7i6YNBmWJZGyaLWr0hOzgKgvl7UED6xYLlUHv/fiEL\n",
              "pkc+IrKXnQTNkDJ5pMtEl457iARzsqnoVtapqtZ25jSs7LlMcdWOpRLRyzmv7gpoAAAAN0GeykUV\n",
              "LCf/AAADADib8iaguiCUyNZAUk7vPHV5aEw3LIfPwz3p21He3pxbLHinx2SuEPjYBF0AAAAvAZ7p\n",
              "dEI/AAADAEN7u/ZGwi5Ki1AI0RKX01GznQQMbqKZ0y6vHB0wWJUFFNY0BJwAAAAvAZ7rakI/AAAD\n",
              "AENa1ozg1smRqABBaEi08VaEA66JOJvYLw9R+IGcikBfahUAm4AAAAB7QZrwSahBbJlMCGf//p4Q\n",
              "AAADANPwnQtshkBQBPKLHKYSsakuLNtWR7/Smi+LKcDlWDFbgJcUell5DczDKIOIVWZ4YKvvW1KK\n",
              "wxZW92/V14cZldkxMSmScosi6NuZXPHM41WWVPQDBdwTGCSXaFBfI0YwWRB19PUYgOmBAAAAQEGf\n",
              "DkUVLCf/AAADADig81uHVj14EkcWunYRTL0Vv2J4mizJkE32vTsZ9bqADaOhtB28Ne4YcpKfA497\n",
              "BhgATcEAAAArAZ8tdEI/AAADAENUcPxaLQAzDqnFPVHEOwFRwIPewnpyDLNeUalbzdAJuQAAACcB\n",
              "ny9qQj8AAAMAQUjY8h1fQdbC1WzgRB2V30E0dmzQ31lmeiQAN6AAAABWQZs0SahBbJlMCF///oyw\n",
              "AAADAM8sGmN2Oaz5ADKx0vXnRBaIpB7eob2YWztJWnJG3uH4Ts5L1Il+ngouzaPZJhBAHkG3AmYe\n",
              "jOQdbjH7YAiqmHMAAYsAAAArQZ9SRRUsJ/8AAAMANz7llxb4QcPkpPnPoickAl92WAr0r4Kfi94H\n",
              "YABSQQAAACcBn3F0Qj8AAAMAQVQoJIb8xPdghXRVxbfmLfiJO9oAN1c7SJqwDFgAAAAfAZ9zakI/\n",
              "AAADAEF2UjbGLwV/XAwrILa/Y+elmMAUEAAAAD1Bm3hJqEFsmUwIV//+OEAAAAMDI2E3RsQBD45m\n",
              "UyE3JRjXywv0aF3kxHYI4u+wtN5ueNRCbhnaW65wgHhBAAAAJ0GflkUVLCf/AAADADc9yP0sOnun\n",
              "wHm5C/OLYT4I8iwhQ88bciAPmAAAAB0Bn7V0Qj8AAAMAQXs3Cbs/SPb6mYvrll7CwQBdwQAAAB0B\n",
              "n7dqQj8AAAMAQVm5D7/4eJN0GSkGp1V4dwAakQAAACxBm7pJqEFsmUwUTCP//eEAAAMADDh6F1c5\n",
              "oc6xwFSINzBdF5yXR/QvUZAF3AAAABwBn9lqQj8AAAMAQVm1hs2n+3pEKk+1qO901QNrAAAI9m1v\n",
              "b3YAAABsbXZoZAAAAAAAAAAAAAAAAAAAA+gAAAwDAAEAAAEAAAAAAAAAAAAAAAABAAAAAAAAAAAA\n",
              "AAAAAAAAAQAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIAAAgg\n",
              "dHJhawAAAFx0a2hkAAAAAwAAAAAAAAAAAAAAAQAAAAAAAAwDAAAAAAAAAAAAAAAAAAAAAAABAAAA\n",
              "AAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAQAAAAAKAAAAB4AAAAAAAJGVkdHMAAAAcZWxzdAAA\n",
              "AAAAAAABAAAMAwAAAgAAAQAAAAAHmG1kaWEAAAAgbWRoZAAAAAAAAAAAAAAAAAAAKAAAAHsAVcQA\n",
              "AAAAAC1oZGxyAAAAAAAAAAB2aWRlAAAAAAAAAAAAAAAAVmlkZW9IYW5kbGVyAAAAB0NtaW5mAAAA\n",
              "FHZtaGQAAAABAAAAAAAAAAAAAAAkZGluZgAAABxkcmVmAAAAAAAAAAEAAAAMdXJsIAAAAAEAAAcD\n",
              "c3RibAAAALdzdHNkAAAAAAAAAAEAAACnYXZjMQAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAAKAAeAA\n",
              "SAAAAEgAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABj//wAAADVhdmND\n",
              "AWQAH//hABhnZAAfrNlAoD2hAAADAAEAAAMAUA8YMZYBAAZo6+PLIsD9+PgAAAAAHHV1aWRraEDy\n",
              "XyRPxbo5pRvPAyPzAAAAAAAAABhzdHRzAAAAAAAAAAEAAAB7AAABAAAAABRzdHNzAAAAAAAAAAEA\n",
              "AAABAAAD6GN0dHMAAAAAAAAAewAAAAEAAAIAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAA\n",
              "AQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAA\n",
              "AAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIA\n",
              "AAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAA\n",
              "AAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAA\n",
              "AAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAA\n",
              "AQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAAB\n",
              "AAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEA\n",
              "AAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAA\n",
              "BQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAAB\n",
              "AAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAA\n",
              "AAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAA\n",
              "AAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAA\n",
              "AAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAA\n",
              "AQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAAB\n",
              "AAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEA\n",
              "AAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAA\n",
              "AgAAAAABAAAAAAAAAAEAAAEAAAAAAQAAAwAAAAABAAABAAAAABxzdHNjAAAAAAAAAAEAAAABAAAA\n",
              "ewAAAAEAAAIAc3RzegAAAAAAAAAAAAAAewAAFk0AAADfAAAAMwAAACQAAAAyAAAA1wAAADUAAAAo\n",
              "AAAAHAAAAHkAAAAzAAAAIwAAACAAAACHAAAAMQAAACAAAAArAAAAlwAAAD4AAAAiAAAAJAAAAKcA\n",
              "AABVAAAANAAAAC0AAACCAAAATwAAACoAAAAmAAAAqgAAAHEAAAArAAAANAAAAKsAAABWAAAAOQAA\n",
              "ADMAAACmAAAAWgAAADgAAAAzAAAA0wAAAFwAAAAyAAAANgAAAMIAAABYAAAANgAAADcAAACpAAAA\n",
              "WgAAADIAAABJAAAAugAAAEwAAAA8AAAAOAAAAJcAAABYAAAAOgAAADUAAACtAAAAWAAAADkAAABG\n",
              "AAAAqQAAAFIAAAA4AAAAMQAAALcAAABkAAAASAAAAEIAAACxAAAAZAAAAEAAAAA7AAAArQAAAFAA\n",
              "AABWAAAAPAAAAMgAAABcAAAAOgAAADwAAADQAAAAWQAAADcAAAA2AAAAsgAAAE4AAAA7AAAAQgAA\n",
              "AMkAAAA/AAAANQAAADYAAADNAAAASwAAADwAAABBAAAAzAAAAEEAAAA8AAAALQAAAH8AAAA7AAAA\n",
              "MwAAADMAAAB/AAAARAAAAC8AAAArAAAAWgAAAC8AAAArAAAAIwAAAEEAAAArAAAAIQAAACEAAAAw\n",
              "AAAAIAAAABRzdGNvAAAAAAAAAAEAAAAwAAAAYnVkdGEAAABabWV0YQAAAAAAAAAhaGRscgAAAAAA\n",
              "AAAAbWRpcmFwcGwAAAAAAAAAAAAAAAAtaWxzdAAAACWpdG9vAAAAHWRhdGEAAAABAAAAAExhdmY1\n",
              "OC43Ni4xMDA=\n",
              "\">\n",
              "  Your browser does not support the video tag.\n",
              "</video>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|████▉     | 49968/100000 [02:55<02:09, 385.11it/s, eval_return=139, eval_ep_len=139, eval/return_std=4.83, eval/return_max=149, eval/return_min=132, eval/ep_len_std=4.83, eval/ep_len_max=149, eval/ep_len_min=132, critic_loss=1.64, q_values=24.1, target_values=24.1, grad_norm=9.69, epsilon=0.55, lr=0.0001]/usr/local/lib/python3.10/dist-packages/gym/core.py:43: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  deprecation(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CWrlmUuN_Nq9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}